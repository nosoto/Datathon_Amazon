{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataTuna_Lasso.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "####\n",
        "from sklearn.svm import SVR\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.cluster import KMeans\n",
        "from pandas import to_datetime\n",
        "#!pip install fbprophet\n",
        "from fbprophet import Prophet\n",
        "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "qqEMP6UdbRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read in Dataset as df, get country code dummies, and change date_time\n",
        "\n",
        "## Load Data Sets\n",
        "train = pd.read_csv('train_data.csv')\n",
        "pd.to_datetime(train['ofd_date'], infer_datetime_format=True) \n",
        "train['y'] = train['Earlies_Exp'] - train['MNR_SNR_Exp']\n",
        "test = pd.read_csv('test.csv')\n",
        "pd.to_datetime(test['ofd_date'], infer_datetime_format=True) \n",
        "test['y'] = 0\n",
        "\n",
        "## Only choose columns from test in train\n",
        "train = train[test.columns[1:]]\n",
        "\n",
        "#Remove Outliers Training Set\n",
        "for column in ['y', 'OFD', 'Slam','Earlies_Rec','Rollover','Returns','R_Sideline','Sideline']:\n",
        "  train[column] = winsorize(train[column], limits=(0.05, 0.05))\n",
        "\n",
        "## Add test to training data for processing\n",
        "train = train.append(test)\n",
        "#train"
      ],
      "metadata": {
        "id": "JtZOYeCWbVlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset Index and Sort Data Set\n",
        "train = train.sort_values(by = ['ofd_date', 'station_code'])\n",
        "train = train.reset_index(drop = True)\n",
        "train = train.drop(['Unnamed: 0'], axis = 1)\n",
        "#train"
      ],
      "metadata": {
        "id": "tqD4gla7a2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Month, Day, Weekday Variables from Date\n",
        "train['Id'] =train[\"ofd_date\"]+ \"_\" + train[\"station_code\"].map(str)\n",
        "train.ofd_date = pd.to_datetime(train.ofd_date)\n",
        "month = train['ofd_date'].dt.month\n",
        "day = train['ofd_date'].dt.day\n",
        "weekday = train['ofd_date'].dt.weekday\n",
        "train_dates = train.copy()\n",
        "train_dates['day'] = day\n",
        "train_dates['weekday'] = weekday\n",
        "train_dates['month'] = month\n",
        "train_dates.set_index('Id', inplace = True)\n",
        "#train_dates"
      ],
      "metadata": {
        "id": "wYCUz8gVLvJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Date and Fc Codes\n",
        "df = train_dates.drop(['ofd_date', 'fc_codes'], axis = 1)\n",
        "#df"
      ],
      "metadata": {
        "id": "faNl5YhVLt-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Lags for all the variables\n",
        "def create_lags(data, no_lags):\n",
        "  for i in range(1, int(no_lags))):\n",
        "    data[\"lag_{}_Earlies_Rec\".format(i)] = data.Earlies_Rec.shift(i)\n",
        "    data[\"lag_{}_OFD\".format(i)] = data.OFD.shift(i)\n",
        "    data[\"lag_{}_Slam\".format(i)] = data.Slam.shift(i)\n",
        "    data[\"lag_{}_Rollover\".format(i)] = data.Rollover.shift(i)\n",
        "    data[\"lag_{}_Returns\".format(i)] = data.Returns.shift(i)\n",
        "    data[\"lag_{}_Slideline\".format(i)] = data.Sideline.shift(i)\n",
        "  return data\n",
        "\n",
        "df_lags = create_lags(df, 61)\n",
        "#df_lags"
      ],
      "metadata": {
        "id": "0mDXpnYtbW6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoding Country Codes and making DC numerical, creating new features\n",
        "df_encoded = pd.get_dummies(df_lags, columns = ['country_code'])\n",
        "df_encoded['DC'] = df_encoded['station_code'].str[1:]\n",
        "df_encoded = df_encoded.drop(['station_code'], axis = 1)\n",
        "df_encoded['DC'] = pd.to_numeric(df_encoded['DC'])\n",
        "#df_encoded\n",
        "\n",
        "feature_transform = df_encoded.columns.to_list()\n",
        "for feature in feature_transform:\n",
        "  df_encoded[f'{feature}_sqrd'] = df_encoded[feature].pow(2)\n",
        "  df_encoded[f'{feature}_p3'] = df_encoded[feature].pow(3)\n",
        "#df_encoded.shape"
      ],
      "metadata": {
        "id": "KT9RHdSzJET1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e741de-5916-4d05-8d63-6bed7631ed00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13698, 1128)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a correaltion Matrix\n",
        "corr = df_encoded.corr()"
      ],
      "metadata": {
        "id": "yPv3Nwg_z12w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Filtering strong correlation\n",
        "strong_var_pos = corr.loc[corr['y'] > 0].index.to_list()\n",
        "strong_var_neg = corr.loc[corr['y'] < 0].index.to_list()\n",
        "strong_var_pos.extend(strong_var_neg)"
      ],
      "metadata": {
        "id": "IAuaw5kzR4Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Only select the strong correlated variables + Days & DC\n",
        "df_strong =  df_encoded[[c for c in df_encoded.columns if c in strong_var_pos]]\n",
        "#df_strong.shape"
      ],
      "metadata": {
        "id": "X9ZEFNxOPclV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the Three batches\n",
        "df_train = df_strong.loc[df_strong['month'] != 7]\n",
        "df_train = df_train.loc[df_strong['month'] != 2]\n",
        "f_train = df_train.loc[df_strong['month'] != 6]\n",
        "df_train = df_train.loc[df_strong['month'] != 3]\n",
        "df_test = df_strong.loc[df_strong['month'] == 6]"
      ],
      "metadata": {
        "id": "4MfqL3FBPhwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the X and Y for the threee batches\n",
        "y_train = df_train['y']\n",
        "y_test = df_test['y']\n",
        "X_train = df_train.drop(['y'], axis = 1)\n",
        "X_test = df_test.drop(['y'], axis = 1)"
      ],
      "metadata": {
        "id": "9Rq0jeV0uRL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run and Test the Model\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "## Define K-Fold\n",
        "cv = RepeatedKFold(n_splits=20, n_repeats=10, random_state=1)\n",
        "alphas = [1]\n",
        "\n",
        "## Run Model, with and without scaling\n",
        "model = Lasso(alpha = 0.999999999)\n",
        "#scaler = MinMaxScaler()\n",
        "#model = make_pipeline(scaler, LinearRegression())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "## Make Predicition\n",
        "y_pred = model.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "UJRQaXGeeTpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Expected & ID Column\n",
        "# Create df with Predictions\n",
        "df_EXP = pd.DataFrame(y_pred, columns = ['Expected'])\n",
        "# Create DF with IDs\n",
        "df_test_ID = df_test[['y']]\n",
        "df_test_ID['Id'] = df_test_ID.index\n",
        "df_test_ID['Id'] = df_test_ID[['Id']]\n",
        "df_test_ID = df_test_ID.reset_index(drop=True)\n",
        "\n",
        "# Create Final DF that joins predictions & ID\n",
        "final=pd.concat([df_test_ID,df_EXP],axis=1,ignore_index=True)\n",
        "final = final[[1,2]]\n",
        "final"
      ],
      "metadata": {
        "id": "RFwH44tO0x5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data for submission\n",
        "from google.colab import drive\n",
        "drive.mount('drive/', force_remount=False)\n",
        "final.to_csv('linear_squared.csv')\n",
        "!cp linear_squared.csv \"drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyev5bGFCEvw",
        "outputId": "ba63df11-8534-4f14-8366-6576b1f4b7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive/\n"
          ]
        }
      ]
    }
  ]
}