{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataTuna_Prophet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHtkDVnQn8kQ"
      },
      "outputs": [],
      "source": [
        "####\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.cluster import KMeans\n",
        "from pandas import to_datetime\n",
        "!pip install prophet\n",
        "import prophet\n",
        "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Read in Dataset as df, get country code dummies, and change date_time\n",
        "df = pd.read_csv('train_data.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "df = pd.get_dummies(df, columns = ['country_code'])\n",
        "pd.to_datetime(df['ofd_date'], infer_datetime_format=True) "
      ],
      "metadata": {
        "id": "EgFG2mkxocr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove Outliers\n",
        "for column in ['OFD', 'Slam', 'Earlies_Exp','Earlies_Rec','MNR_SNR_Exp','Rollover','Returns','R_Sideline','Sideline']:\n",
        "  df[column] = winsorize(df[column], limits=(0.05, 0.05))"
      ],
      "metadata": {
        "id": "pbCfSScjor_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cluster + Encode based on Mean of MNR SNR Exp and Earlies Exp\n",
        "def encode_and_clster(df, var1, var2, n_clusters):\n",
        "  # Encode based on two means\n",
        "  df_1 = pd.DataFrame(df.groupby(by=[df.station_code], as_index = False).mean())\n",
        "  df_1 = df_1.drop(columns = [x for x in list(df.columns) if 'country_code' in x])\n",
        "  # Encode based on two means\n",
        "  me_var1 = df_1.groupby('station_code')[var1].mean()\n",
        "  df_1.loc[:, 'en_var1'] = df_1['station_code'].map(me_var1)\n",
        "  me_var2 = df_1.groupby('station_code')[var2].mean()\n",
        "  df_1.loc[:, 'en_var2'] = df_1['station_code'].map(me_var2)\n",
        "  # Create Sum of those two means\n",
        "  df_1['mean_encode'] = df_1['en_var1'] + df_1['en_var2']\n",
        "\n",
        "  # Create Cluster\n",
        "  df_cluster = df_1[[ 'OFD', 'Slam','Earlies_Exp', 'Earlies_Rec', 'MNR_SNR_Exp', 'Rollover', \n",
        "                  'Returns', 'R_Sideline', 'Sideline', 'mean_encode']]\n",
        "  kmean = KMeans(n_clusters=n_clusters, random_state=0).fit(df_cluster)\n",
        "  # Map DC to New Clusters\n",
        "  df_mapping = list(kmean.predict(df_cluster))\n",
        "  dict = {}\n",
        "  for i in range(0, len(df_mapping)):\n",
        "    dict[df_1['station_code'][i]] = df_mapping[i]\n",
        "\n",
        "    \n",
        "  def conversion_function(value):\n",
        "    return dict[value]\n",
        "  \n",
        "  df['DC'] = df['station_code'].apply(conversion_function)\n",
        "  return df\n",
        "\n",
        "df_new = encode_and_clster(df, 'OFD', 'Slam', 7)"
      ],
      "metadata": {
        "id": "4dkdIx8OqL_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PROPHET MODEL\n",
        "\n",
        "# Prepare Data. Get unique Datacenters and prepare df in a way Prophet can handle (target = yhat, date = ds)\n",
        "codes = df_new['station_code'].unique()\n",
        "pandas = pd.DataFrame(np.array([[0, 0, 0]]),columns=['ds', 'yhat', 'DC'])\n",
        "\n",
        "# Define Function to run Prophet Model and return forecast\n",
        "def run_prophet(var_to_predidct, train, test):\n",
        "  # Select Var to Predict & Date\n",
        "  train = train[[var_to_predidct, 'ofd_date']]\n",
        "  # Change to datetime\n",
        "  train['ds']= to_datetime(train['ofd_date'])\n",
        "  train['y']= to_datetime(train[var_to_predidct])\n",
        "  # Fit & Run Model\n",
        "  model = Prophet(weekly_seasonality=True)\n",
        "  model.fit( train)\n",
        "  forecast = model.predict(test)\n",
        "  # Return Forecast\n",
        "  return forecast[['ds','yhat']]\n",
        "\n",
        "## For each Data Center call prophet function\n",
        "\n",
        "for DC in codes:\n",
        "  # Filter Data for DataCenter\n",
        "  df_new_test = df_new.loc[df_new['station_code'] == DC]\n",
        "  test['ds'] = test_df['ofd_date']\n",
        "  test = test_df.loc[test_df['station_code'] == DC][['ds']]\n",
        "  # Run Prophet Model on Earliers Exp and MNR_SNR_EXP\n",
        "  forecast_1 = run_prophet('Earlies_Exp', df_new_test, test)\n",
        "  forecast_2 = run_prophet('MNR_SNR_Exp', df_new_test, test)\n",
        "  # Create Forecast\n",
        "  forecast_target = forecast_1['yhat']-forecast_2['yhat']\n",
        "  forecast = pd.DataFrame(forecast_target)\n",
        "  forecast['ds'] = forecast_1['ds']\n",
        "  forecast['DC'] = DC\n",
        "  # Add to final Data Frame\n",
        "  pandas = pandas.append(forecast)\n"
      ],
      "metadata": {
        "id": "nACCSlJYA55Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Wrangle Data Frame so that it is in the format ready for submission\n",
        "# Create two copies to avoid overwriting\n",
        "panda = pandas\n",
        "panda_New = panda\n",
        "# Extract data variable in the way we need it\n",
        "panda_New['ds'] = panda[panda['ds'].map(str)].str.split(' ',expand=True)[0]\n",
        "# Change name of Target to Expected\n",
        "panda['Expected'] = panda['yhat']\n",
        "# Create final ID variable\n",
        "panda['Id'] = panda_New['ds']\n",
        "panda_final = panda[['Id', 'Expected', 'DC']]\n",
        "panda_final['Id_new'] =panda_final[\"Id\"]+ \"_\" + panda_final[\"DC\"].map(str)\n",
        "panda_final['Id'] = panda_final['Id_new']\n",
        "# Build final DF\n",
        "panda_final = panda_final[['Id', 'Expected']]"
      ],
      "metadata": {
        "id": "uV_L0sOzdUx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive and export\n",
        "from google.colab import drive\n",
        "drive.mount('drive/', force_remount=False)\n",
        "panda_final.to_csv('data_prophet.csv')\n",
        "!cp data_prophet.csv \"drive/My Drive/\""
      ],
      "metadata": {
        "id": "dF4-yWsndR54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uWkVqssDaHZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}