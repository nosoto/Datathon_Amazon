{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486480d2-029d-4d42-adea-4fa6d260dafc",
   "metadata": {},
   "source": [
    "# DataTuna Final Model Submission\n",
    "Nora Tombers, Alvaro Prior, Nicolo Prini, Philippe Henderson\n",
    "\n",
    "Note: This "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afae23d-d5b9-484f-9306-0bd197621152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import data_processor_full, data_processor_full_jun\n",
    "from helper_functions import split_function_large, feature_ranker, split_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from functools import partial\n",
    "from scipy.stats.mstats import winsorize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff11e26-9f37-4962-94d7-6bc1e2a45bd1",
   "metadata": {},
   "source": [
    "### Supporting Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c5594-a8b8-4814-b215-f049dcb7bc14",
   "metadata": {},
   "source": [
    "#### Outlier Management:\n",
    "- Winsorizes columns based on a pre-defined upper and lower outlier threshold (in percentage terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6e3b-cb49-44aa-9336-c641e0c420ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_management(df, column_list, perc_limit=0.025):\n",
    "    for column in column_list:\n",
    "        df[column] = winsorize(df[column], limits=(perc_limit, perc_limit))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfca30-1e64-468d-b04f-0dfdb18e5e37",
   "metadata": {},
   "source": [
    "#### addSimpleLags_Diffs\n",
    "-> This function uses a partial function (_buildLags_Diffs_) to process individual lags. We're essentially bulk applying a single lag (using map) to all columns at once).\n",
    "\n",
    "- **Inputs**:\n",
    "    - **df**: DataFrame to modify, \n",
    "    - **lag_list**: list of periods of lags or diffs to do (ex. 1 = lag by 1 row, or subtract previous row on current row),\n",
    "    - **col_list**: list of columns to apply the lagging/diff(ing) to,\n",
    "    - **change_choice**: either lag, lead, or diff (diff will by default be backwards diff).\n",
    "- **Output**:\n",
    "    - Modified DF <- dtypes: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f166f-9b08-4e62-8098-1fba5cbd7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSimpleLags_Diffs(df, lag_list, col_list, change_choice='lag'):\n",
    "    if change_choice == 'lead':\n",
    "        lag_list = map(lambda x: x * (-1), lag_list)\n",
    "\n",
    "    arr_lags = list(map(partial(_buildLags_Diffs, df=df,\n",
    "                                col_list=col_list,\n",
    "                                change_choice=change_choice),\n",
    "                        lag_list))\n",
    "\n",
    "    df = pd.concat([df] + arr_lags, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _buildLags_Diffs(lag, df, col_list, change_choice):\n",
    "    if change_choice == 'lag' or change_choice == 'lead':\n",
    "        return df.groupby('station_code')[col_list].shift(lag).add_suffix(f'_{np.abs(lag)}_{change_choice}')\n",
    "    elif change_choice == 'diff':\n",
    "        return df.groupby('station_code')[col_list].diff(lag).add_suffix(f'_{np.abs(lag)}_{change_choice}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b68489-1b8c-4685-9172-fdf06073475c",
   "metadata": {},
   "source": [
    "#### data_processor_full - AKA Big Bertha\n",
    "- So much goes on here. It's late. I'm not sure I have the energy to explain it all....\n",
    "\n",
    "- TL;DR: Takes in the train + test datasets and calculates all the features, with some help from the supporting functions above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2b63d-4d1e-4a40-9a2b-8248547629f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processor_full(train_df, target_df, dep_vars, date_col, date_cols_ToDo,\n",
    "                        lag_ToDo=[1, 2, 4, 5, 6, 7],\n",
    "                        diff_ToDo=None,\n",
    "                        outlier_threshold=0.025, lagChoice='both', cutoff_date = '2021-07-01', verbose=False):\n",
    "\n",
    "    train_df.sort_values(by=date_col, ascending=True, inplace=True)\n",
    "    target_df.sort_values(by=date_col, ascending=True, inplace=True)\n",
    "\n",
    "    LagDiff_vars_ToDo = [x for x in list(train_df.select_dtypes(['int64']).columns) if x not in dep_vars]\n",
    "    encode_basevars_ToDo = [x for x in list(train_df.select_dtypes(['object']).columns) if\n",
    "                            x != date_col and x != 'station_code']\n",
    "\n",
    "    train_df = outlier_management(train_df, LagDiff_vars_ToDo, outlier_threshold)\n",
    "    target_df = outlier_management(target_df, LagDiff_vars_ToDo, outlier_threshold)\n",
    "\n",
    "    target_df.drop(columns=target_df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    train_target_vars = train_df[['ofd_date', 'station_code'] + dep_vars]\n",
    "    train_df.drop(columns=dep_vars, inplace=True)\n",
    "\n",
    "    full_data_to_process = pd.concat([train_df, target_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    if lagChoice == 'both':\n",
    "        full_data_to_process = addSimpleLags_Diffs(full_data_to_process, lag_ToDo, LagDiff_vars_ToDo, change_choice='lag')\n",
    "        full_data_to_process = addSimpleLags_Diffs(full_data_to_process, diff_ToDo, LagDiff_vars_ToDo, change_choice='diff')\n",
    "\n",
    "    elif lagChoice in ['lag', 'diff', 'lead']:\n",
    "        full_data_to_process = addSimpleLags_Diffs(full_data_to_process, lag_ToDo, LagDiff_vars_ToDo, change_choice=lagChoice)\n",
    "\n",
    "\n",
    "    full_data_to_process = full_data_to_process.fillna(0)\n",
    "\n",
    "    # Encode columns. DC should be excluded from this as we do a special encoding.\n",
    "    full_data_to_process.drop(columns=encode_basevars_ToDo, inplace=True)\n",
    "\n",
    "\n",
    "    train_data_processed = full_data_to_process[full_data_to_process.ofd_date < cutoff_date]\n",
    "    train_data_processed = train_data_processed[train_data_processed.ofd_date > '2021-03-02']\n",
    "    train_Y = train_target_vars[train_target_vars.ofd_date > '2021-03-02']\n",
    "    test_data_processed = full_data_to_process[full_data_to_process.ofd_date >= cutoff_date]\n",
    "\n",
    "\n",
    "    train_Y['ofd_date'] = train_Y.ofd_date.astype('datetime64[ns]')\n",
    "    train_data_processed['ofd_date'] = train_data_processed.ofd_date.astype('datetime64[ns]')\n",
    "    train_Y['station_code'] = train_Y.station_code.astype(str)\n",
    "    train_data_processed['station_code'] = train_data_processed.station_code.astype(str)\n",
    "\n",
    "    final_train_all = pd.merge(train_data_processed, train_Y, on=[\"ofd_date\", 'station_code'], how=\"left\")\n",
    "\n",
    "    final_train_all['station_code'] = final_train_all['station_code'].apply(lambda x: int(x[1:]))\n",
    "\n",
    "    test_data_processed['station_code'] = test_data_processed['station_code'].apply(lambda x: int(x[1:]))\n",
    "\n",
    "\n",
    "    final_train_all.reset_index(drop=True, inplace=True)\n",
    "    train_data_processed.reset_index(drop=True, inplace=True)\n",
    "    train_Y.reset_index(drop=True, inplace=True)\n",
    "    test_data_processed.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if verbose:\n",
    "        for column in list(full_data_to_process.columns):\n",
    "            print(column)\n",
    "    else:\n",
    "        print(\"Data processing is done.\")\n",
    "        print(f\"We now have {len(list(full_data_to_process.columns))} features. Woop woop.\")\n",
    "\n",
    "\n",
    "    return final_train_all, test_data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2a540-0289-40e0-b56c-112efae45e12",
   "metadata": {},
   "source": [
    "#### Training Data Splitting functions\n",
    "- **split_function:** will just split train data into two splits: train + test\n",
    "- **split_function_large:** will split train data into two training datasets + one test. This is used for the feature selection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7b99a-1e47-40fa-9fa7-3018323eb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_function(df, target_var, train_perc=.8):\n",
    "    all_dates_unique = df['ofd_date'].unique()\n",
    "\n",
    "    cutoff_date = all_dates_unique[int(len(all_dates_unique) * train_perc)]\n",
    "\n",
    "    train_data = df[df.ofd_date < cutoff_date]\n",
    "    test_data = df[df.ofd_date >= cutoff_date]\n",
    "\n",
    "    train_data.set_index(['ofd_date'], inplace=True)\n",
    "    test_data.set_index(['ofd_date'], inplace=True)\n",
    "\n",
    "    train_X, train_Y = train_data.drop(target_var, axis=1), train_data[target_var]\n",
    "    test_X, test_Y = test_data.drop(target_var, axis=1), test_data[target_var]\n",
    "\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2ae07-4002-4ff4-8272-d5b211284b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_function_large(df, target_var, train_perc1=.7, train_perc2=.2):\n",
    "    all_dates_unique = df['ofd_date'].unique()\n",
    "\n",
    "    cutoff_date_one = all_dates_unique[int(len(all_dates_unique) * train_perc1)]\n",
    "    cutoff_date_two = all_dates_unique[int(len(all_dates_unique) * (train_perc1 + train_perc2))]\n",
    "\n",
    "    train_data_one = df[df.ofd_date < cutoff_date_one]\n",
    "    mask = ((df['ofd_date'] >= cutoff_date_one) & (df['ofd_date'] < cutoff_date_two))\n",
    "    train_data_two = df.loc[mask]\n",
    "    test_data = df[df.ofd_date >= cutoff_date_two]\n",
    "\n",
    "    train_data_one.set_index(['ofd_date'], inplace=True)\n",
    "    train_data_two.set_index(['ofd_date'], inplace=True)\n",
    "    test_data.set_index(['ofd_date'], inplace=True)\n",
    "\n",
    "    train_X_one, train_Y_one = train_data_one.drop(target_var, axis=1), train_data_one[target_var]\n",
    "    train_X_two, train_Y_two = train_data_two.drop(target_var, axis=1), train_data_two[target_var]\n",
    "    test_X, test_Y = test_data.drop(target_var, axis=1), test_data[target_var]\n",
    "\n",
    "    return train_X_one, train_Y_one, train_X_two, train_Y_two, test_X, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b76c2-8b5f-403a-8713-ca60dea7a670",
   "metadata": {},
   "source": [
    "## Feature Selection Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef70980-4fce-49f9-916c-8c286801937e",
   "metadata": {},
   "source": [
    "return_columns: Just searches for the features with a given importance weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1af67-5773-4b0f-9dbb-486fddc90e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_columns(dict, threshold):\n",
    "    column_list = []\n",
    "    for feature in dict.keys():\n",
    "        if dict[feature] >= threshold:\n",
    "            column_list.append(feature)\n",
    "        else:\n",
    "            continue\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815b15b-e24f-4452-ad82-ba46b430287a",
   "metadata": {},
   "source": [
    "#### cross_val_test\n",
    "- Performs the RMSE estimation (averaged out over nr_cross rounds) for feature selection.\n",
    "- Takes two training sets (second one is used as the eval_set), and a test_set to predict RMSE of the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d2163-8cff-42ee-9a58-8653086f87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_test(nr_cross, select_X_train_one, y_train_one, select_X_train_two, y_train_two, select_X_test, y_test):\n",
    "    all_RMSE = []\n",
    "    for _ in range(nr_cross):\n",
    "        selection_model = xgb.XGBRegressor(n_estimators=250)\n",
    "        selection_model.fit(select_X_train_one, y_train_one,\n",
    "                            eval_set=[(select_X_train_one, y_train_one), (select_X_train_two, y_train_two)],\n",
    "                            early_stopping_rounds=20,\n",
    "                            verbose=False)\n",
    "\n",
    "        preds2 = pd.DataFrame(selection_model.predict(select_X_test))\n",
    "        RMSE = mean_squared_error(y_test, preds2, squared=False)\n",
    "        all_RMSE.append(RMSE)\n",
    "\n",
    "    average_RMSE = sum(all_RMSE) / len(all_RMSE)\n",
    "    return average_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf847a-90ad-4f7e-b9c5-24ad263d906e",
   "metadata": {},
   "source": [
    "#### feature_ranker\n",
    "- Will run a first XGBoost round to get all feature weights, then creates a dict of the features & their scores. \n",
    "- Then we loop through each distinct feature score (in ascending order) and progressively filter out features. \n",
    "- RMSE cross validation is done with the **cross_val_test** function, and the features yielding the best average RMSE are returned to the main model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338f28d-0588-4111-9cb7-99159712f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ranker(x_train_one, y_train_one, x_train_two, y_train_two, x_test, y_test, target_var):\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=1000)\n",
    "    xgb_reg.fit(x_train_one, y_train_one, eval_set=[(x_train_one, y_train_one), (x_train_two, y_train_two)],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=False)\n",
    "\n",
    "    importances = xgb_reg.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "    importances_scores = [x for x in importances.values()]\n",
    "\n",
    "    new_scores = []\n",
    "    for score in importances_scores:\n",
    "        if score not in new_scores:\n",
    "            new_scores.append(score)\n",
    "\n",
    "    new_scores.sort()\n",
    "\n",
    "    preds = pd.DataFrame(xgb_reg.predict(x_test))\n",
    "    RMSE_baseline = mean_squared_error(y_test, preds, squared=False)\n",
    "    print(f\"Base RMSE for {target_var}, All features: {RMSE_baseline}\")\n",
    "\n",
    "    results = {}\n",
    "    for score in new_scores:\n",
    "\n",
    "        features_to_use = return_columns(importances, score)\n",
    "        if 'station_code' not in features_to_use:\n",
    "            features_to_use = features_to_use + ['station_code']\n",
    "        select_X_train_one = x_train_one[features_to_use]\n",
    "        select_X_train_two = x_train_two[features_to_use]\n",
    "        select_X_test = x_test[features_to_use]\n",
    "\n",
    "        avg_RMSE = cross_val_test(5, select_X_train_one=select_X_train_one, y_train_one=y_train_one,\n",
    "                                  select_X_train_two=select_X_train_two, y_train_two=y_train_two,\n",
    "                                  select_X_test=select_X_test, y_test=y_test)\n",
    "\n",
    "        results[avg_RMSE] = features_to_use\n",
    "        print(\n",
    "            f\"Feature Sel. RMSE for {target_var}, Score Threshold: {score}, Total features: {len(features_to_use)}, Average RMSE: {avg_RMSE}\")\n",
    "\n",
    "    lowest_RMSE = min([x for x in results.keys()])\n",
    "    optimal_params = results[lowest_RMSE]\n",
    "    print(f\"Lowest RMSE: {lowest_RMSE} vs. Baseline: {RMSE_baseline}, with {len(optimal_params)} features: {optimal_params} \")\n",
    "    return optimal_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f4420-faf4-43f7-a430-e32226de088b",
   "metadata": {},
   "source": [
    "## Model Tuning + Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7534071a-4981-4715-98ea-843860f709c7",
   "metadata": {},
   "source": [
    "#### The Manager\n",
    "- Manages tasks detailed above: Splitting data using split_function_large, then finding best parameters, then transforming the dataset.\n",
    "- Once that is done, it will then run xGBGrid_FIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0b885-e9e3-41b5-aba4-2a5edf0ceb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_manager_features(full_df_train, target_var, test_data, non_target_var, params):\n",
    "    print(f\"Working on: {target_var}\")\n",
    "    full_df_train.drop(columns=[non_target_var], axis=1, inplace=True)\n",
    "    train_X_one, train_Y_one, train_X_two, train_Y_two, test_X, test_Y = split_function_large(df=full_df_train,\n",
    "                                                                                              target_var=target_var,\n",
    "                                                                                              train_perc1=0.7,\n",
    "                                                                                              train_perc2=0.2)\n",
    "\n",
    "    optimal_features = feature_ranker(x_train_one=train_X_one, y_train_one=train_Y_one, x_train_two=train_X_two,\n",
    "                                      y_train_two=train_Y_two, x_test=test_X, y_test=test_Y, target_var=target_var)\n",
    "\n",
    "\n",
    "    full_train_df_selected = full_df_train[['ofd_date'] + optimal_features + [target_var]]\n",
    "    print(full_train_df_selected)\n",
    "    full_test_selected = test_data[['ofd_date'] + optimal_features]\n",
    "    print(full_test_selected)\n",
    "\n",
    "    train_X, train_Y, validation_X, validation_Y = split_function(df=full_train_df_selected,\n",
    "                                                                  target_var=target_var,\n",
    "                                                                  train_perc=0.8)\n",
    "\n",
    "    optimal_params, final_prediction = xGBGrid_FIND(x_train=train_X, y_train=train_Y, x_validate=validation_X,\n",
    "                                                    y_validate=validation_Y, x_test=full_test_selected,\n",
    "                                                    params=params, target_var=target_var)\n",
    "\n",
    "    return optimal_features, optimal_params, final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea8a88-4b66-4475-a5a2-edc6dbad357a",
   "metadata": {},
   "source": [
    "#### xGBGrid_FIND\n",
    "- Runs HalvingGridSearchCV (instead of GridSearchCV) based on params defined below. \n",
    "- Once optimal model params are found, it will fit to the test data. \n",
    "- Finally, it cleans the predictions and returns it in a nice format for the final prediction data.\n",
    "\n",
    "**Note:** A sharp eye will notice that n_jobs is set pretty high. Don't set it higher, and in fact, set it lower. At 400 I crashed a M1 Max Mac. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac436a6-683a-48cb-8ba2-584172e54e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xGBGrid_FIND(x_train, y_train, x_validate, y_validate, x_test, params, target_var):\n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    grid = HalvingGridSearchCV(xgb_reg, param_grid=params, factor=3, scoring='neg_mean_squared_error', n_jobs=300,\n",
    "                               verbose=3)\n",
    "    # grid = GridSearchCV(xgb_reg, params, scoring=scoring_func, n_jobs=-1, cv=5, verbose=3)\n",
    "    grid.fit(x_train, y_train, eval_set=[(x_validate, y_validate)], early_stopping_rounds=20, verbose=False)\n",
    "    gridcv_xgb = grid.best_estimator_\n",
    "    print(f\"Best Params: {gridcv_xgb}\")\n",
    "\n",
    "\n",
    "    x_base = x_test[['ofd_date', 'station_code']]\n",
    "\n",
    "    x_test = x_test[list(x_train.columns)]\n",
    "    preds = gridcv_xgb.predict(x_test)\n",
    "    preds_df = pd.DataFrame(preds)\n",
    "\n",
    "    final_pred = convert_to_final(x_base, preds_df, target_var)\n",
    "    return gridcv_xgb, final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028486d-c20a-4000-ae56-e0f28d2b43a1",
   "metadata": {},
   "source": [
    "## Supporting functions to prediction -> Just to clean predictions into right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42673a-74d3-46ce-937d-5a1f893a13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_final(test_X, preds, var):\n",
    "    colname = 'yhat_' + str(var)\n",
    "    preds[colname] = preds[0]\n",
    "    test_X = test_X.reset_index()\n",
    "\n",
    "    full_prediction = test_X.join(preds)\n",
    "    print(full_prediction)\n",
    "    full_prediction = full_prediction[['ofd_date', 'station_code', colname]]\n",
    "    return full_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676a81c-44ac-4b90-b2f0-7155f69f18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_merger(mnr_df, earlies_df):\n",
    "    mnr_df.reset_index(drop=True, inplace=True)\n",
    "    earlies_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    forecast_full = pd.merge(mnr_df, earlies_df, how=\"left\", on=[\"ofd_date\", \"station_code\"])\n",
    "    forecast_full['Expected'] = forecast_full['yhat_Earlies_Exp'] - forecast_full['yhat_MNR_SNR_Exp']\n",
    "\n",
    "    forecast_full['Id'] = forecast_full['ofd_date'].astype(str) + \"_D\" + forecast_full['station_code'].astype(str)\n",
    "\n",
    "    forecast_final_result = forecast_full[['Id', 'Expected']]\n",
    "    return forecast_final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a793445-c378-4811-b623-68d6b00566bc",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e0209-f3fa-480e-9218-4cd971cd3ed9",
   "metadata": {},
   "source": [
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdaa969-708c-43f4-a523-45d3d378df92",
   "metadata": {},
   "source": [
    "We create a lot of lags and diff (day0 - day(-1) ) columns to provide the model with information as to past events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb6648-29dc-4883-a814-9110d59f01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = [['MNR_SNR_Exp', 'Earlies_Exp'], ['Earlies_Exp', 'MNR_SNR_Exp']]\n",
    "base_date_col = 'ofd_date'\n",
    "\n",
    "\n",
    "lag_to_do = []\n",
    "for x in range(1, 31):\n",
    "    lag_to_do.append(x)\n",
    "    \n",
    "diff_to_do = []\n",
    "for x in range(1, 22):\n",
    "    diff_to_do.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2bf4b-6fec-47a1-8a19-f6c5ec741d4d",
   "metadata": {},
   "source": [
    "#### Parameters for HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a435b-5bfb-4578-bedd-6d2e6f6bf27d",
   "metadata": {},
   "source": [
    "Many parameters. Hence using HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e560f6-c217-439e-8843-be7139b4f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "xGparams_high = {\n",
    "        'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
    "        'n_estimators': [500, 700],\n",
    "        'min_child_weight': [4, 5],\n",
    "        'gamma': [i / 10.0 for i in range(4, 6)],\n",
    "        'subsample': [i / 10.0 for i in range(8, 11)],\n",
    "        'colsample_bytree': [i / 10.0 for i in range(8, 11)],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b537dc1-5cee-4e05-8a0d-60bcf13b9180",
   "metadata": {},
   "source": [
    "#### Big Momma Part II\n",
    "- Loops through the two base target variables (MNR_SNR_Exp and Earlies_Exp).\n",
    "- Preps the data, then runs the model_manager to select best features, find best parameters, and make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0165a2c-f2ca-46f8-be40-7707765a4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data processor\n",
    "results_dict = {}\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "synth_tests = []\n",
    "\n",
    "early_testing = False\n",
    "\n",
    "for i in range(len(target_vars)):\n",
    "    train_data = pd.read_csv('./train_data.csv', sep=',')\n",
    "    test_data = pd.read_csv('./test.csv', sep=',')\n",
    "\n",
    "\n",
    "    final_all_train, test_data_processed = data_processor_full(\n",
    "        train_df=train_data,\n",
    "        target_df=test_data,\n",
    "        dep_vars=['Earlies_Exp', 'MNR_SNR_Exp'],\n",
    "        lag_ToDo=lag_to_do,\n",
    "        diff_ToDo=diff_to_do,\n",
    "        outlier_threshold=0.025,\n",
    "        lagChoice='both',\n",
    "        cutoff_date='2021-07-01',\n",
    "        verbose=False)\n",
    "\n",
    "    optimal_features, optimal_params, result_prediction = model_manager_features(full_df_train=final_all_train,\n",
    "                                                                                 target_var=target_vars[i][0],\n",
    "                                                                                 test_data=test_data_processed,\n",
    "                                                                                 non_target_var=target_vars[i][1], \n",
    "                                                                                 params=xGparams_low)\n",
    "\n",
    "\n",
    "\n",
    "    results_dict[target_vars[i][0]] = {}\n",
    "    results_dict[target_vars[i][0]]['best_features'] = optimal_features\n",
    "    results_dict[target_vars[i][0]]['best_param'] = optimal_params\n",
    "\n",
    "    result_dfs.append(result_prediction)\n",
    "\n",
    "final_output = final_merger(result_dfs[0], result_dfs[1])\n",
    "print(f\"Final best params for prediction: {results_dict}\")\n",
    "\n",
    "print(final_output)\n",
    "final_output.to_csv('phil_submission_final_squared.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEAvenv",
   "language": "python",
   "name": "deavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
