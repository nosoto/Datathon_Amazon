{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataTuna_LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "####\n",
        "from sklearn.svm import SVR\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.cluster import KMeans\n",
        "from pandas import to_datetime\n",
        "#!pip install fbprophet\n",
        "from fbprophet import Prophet\n",
        "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "qqEMP6UdbRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read in Dataset as df, get country code dummies, and change date_time\n",
        "\n",
        "## Load Data Sets, Create Date & y\n",
        "# Train\n",
        "train = pd.read_csv('train_data.csv')\n",
        "pd.to_datetime(train['ofd_date'], infer_datetime_format=True) \n",
        "train['y'] = train['Earlies_Exp'] - train['MNR_SNR_Exp']\n",
        "# Test\n",
        "test = pd.read_csv('test.csv')\n",
        "pd.to_datetime(test['ofd_date'], infer_datetime_format=True) \n",
        "test['y'] = 0\n",
        "# Only keep columns in trainingset that we have in testset\n",
        "train = train[test.columns[1:]]"
      ],
      "metadata": {
        "id": "JtZOYeCWbVlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove Outliers Training Set\n",
        "for column in ['y', 'OFD', 'Slam','Earlies_Rec','Rollover','Returns','R_Sideline','Sideline']:\n",
        "  train[column] = winsorize(train[column], limits=(0.05, 0.05))"
      ],
      "metadata": {
        "id": "J-D4sc6UXZzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add test to training data for processing (no processing happening that could create data leakage)\n",
        "train = train.append(test)"
      ],
      "metadata": {
        "id": "cIy5oSINXkfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reset Index and Sort Data Set\n",
        "train = train.sort_values(by = ['ofd_date', 'station_code'])\n",
        "train = train.reset_index(drop = True)\n",
        "train = train.drop(['Unnamed: 0'], axis = 1)\n",
        "#train"
      ],
      "metadata": {
        "id": "tqD4gla7a2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Data Variables\n",
        "# ID\n",
        "train['Id'] =train[\"ofd_date\"]+ \"_\" + train[\"station_code\"].map(str)\n",
        "\n",
        "# Month, Day, Weekday\n",
        "train.ofd_date = pd.to_datetime(train.ofd_date)\n",
        "month = train['ofd_date'].dt.month\n",
        "day = train['ofd_date'].dt.day\n",
        "weekday = train['ofd_date'].dt.weekday\n",
        "train_dates = train.copy()\n",
        "train_dates['day'] = day\n",
        "train_dates['weekday'] = weekday\n",
        "train_dates['month'] = month\n",
        "train_dates.set_index('Id', inplace = True)\n",
        "#train_dates"
      ],
      "metadata": {
        "id": "wYCUz8gVLvJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop Date and FC Codes\n",
        "df = train_dates.drop(['ofd_date', 'fc_codes'], axis = 1)\n",
        "#df"
      ],
      "metadata": {
        "id": "faNl5YhVLt-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Lags for all the variables\n",
        "# Define function\n",
        "def create_lags(data, no_lags):\n",
        "  for i in range(1, int(no_lags)):\n",
        "    data[\"lag_{}_Earlies_Rec\".format(i)] = data.Earlies_Rec.shift(i)\n",
        "    data[\"lag_{}_OFD\".format(i)] = data.OFD.shift(i)\n",
        "    data[\"lag_{}_Slam\".format(i)] = data.Slam.shift(i)\n",
        "    data[\"lag_{}_Rollover\".format(i)] = data.Rollover.shift(i)\n",
        "    data[\"lag_{}_Returns\".format(i)] = data.Returns.shift(i)\n",
        "    data[\"lag_{}_Slideline\".format(i)] = data.Sideline.shift(i)\n",
        "  return data\n",
        "\n",
        "# Create 21 Lags\n",
        "df_lags = create_lags(df, 21)\n",
        "#df_lags"
      ],
      "metadata": {
        "id": "0mDXpnYtbW6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoding Country Codes and making DC numerical\n",
        "df_encoded = pd.get_dummies(df_lags, columns = ['country_code'])\n",
        "\n",
        "df_encoded['DC'] = df_encoded['station_code'].str[1:]\n",
        "df_encoded = df_encoded.drop(['station_code'], axis = 1)\n",
        "df_encoded['DC'] = pd.to_numeric(df_encoded['DC'])\n",
        "#df_encoded"
      ],
      "metadata": {
        "id": "KT9RHdSzJET1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Finding strong correlation\n",
        "correlations = df_encoded.corr().sort_values('y')['y']\n",
        "correlations = pd.DataFrame(correlations)\n",
        "#correlations"
      ],
      "metadata": {
        "id": "7fgloSxTJlAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropping Variables with certain correlations\n",
        "corr = df_encoded.corr()\n",
        "strong_var_pos = corr.loc[corr['y'] > 0 ].index.to_list()\n",
        "strong_var_neg = corr.loc[corr['y'] < 0 ].index.to_list()\n",
        "strong_var_pos.extend(strong_var_neg)\n",
        "#strong_var_pos.append('DC')\n",
        "#strong_var_pos.append('day')"
      ],
      "metadata": {
        "id": "IAuaw5kzR4Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Only select the strong correlated variables + Days & DC\n",
        "df_strong =  df_encoded[[c for c in df_encoded.columns if c in strong_var_pos]]\n",
        "#df_strong"
      ],
      "metadata": {
        "id": "X9ZEFNxOPclV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the Three batches\n",
        "df_train = df_strong.loc[df_strong['month'] != 7]\n",
        "df_train = df_strong.loc[df_strong['month'] != 6]\n",
        "df_train = df_train.loc[df_strong['month'] != 2]\n",
        "df_test = df_strong.loc[df_strong['month'] == 6]"
      ],
      "metadata": {
        "id": "4MfqL3FBPhwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the X and Y for the threee batches\n",
        "scaler = StandardScaler()\n",
        "y_train = df_train['y']\n",
        "y_test = df_test['y']\n",
        "X_train = df_train.drop(['y'], axis = 1)\n",
        "X_test = df_test.drop(['y'], axis = 1)"
      ],
      "metadata": {
        "id": "9Rq0jeV0uRL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run and Test the Model\n",
        "regr =  make_pipeline(LinearRegression())\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)"
      ],
      "metadata": {
        "id": "UJRQaXGeeTpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean_squared_error(y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M233dQ8D5jeZ",
        "outputId": "92fb8f7c-fca5-44ae-edc3-09af70a002cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "432.8918894222631"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Expected Column\n",
        "df = pd.DataFrame(y_pred, columns = ['Expected'])\n",
        "#df"
      ],
      "metadata": {
        "id": "RFwH44tO0x5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Id Column\n",
        "df_test = df_test[['y']]\n",
        "df_test['Id'] = df_test.index\n",
        "#df_test = df_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "KeTLTUb83axk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Final DF from Expected & ID\n",
        "final=pd.concat([df_test,df],axis=1,ignore_index=True)\n",
        "final = final[[1,2]]\n",
        "final"
      ],
      "metadata": {
        "id": "GMWXLDWjehLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Export Reults for Sub,ission\n",
        "from google.colab import drive\n",
        "drive.mount('drive/', force_remount=False)\n",
        "final.to_csv('linear_regression.csv')\n",
        "!cp linear_regression.csv \"drive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyev5bGFCEvw",
        "outputId": "7e581fb1-88c3-4924-f2fa-89bf2dad08ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive/\n"
          ]
        }
      ]
    }
  ]
}